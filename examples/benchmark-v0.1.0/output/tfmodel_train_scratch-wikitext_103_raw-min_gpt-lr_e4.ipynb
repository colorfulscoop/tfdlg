{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017076,
     "end_time": "2021-01-01T05:57:36.207787",
     "exception": false,
     "start_time": "2021-01-01T05:57:36.190711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:36.236188Z",
     "iopub.status.busy": "2021-01-01T05:57:36.235816Z",
     "iopub.status.idle": "2021-01-01T05:57:36.237680Z",
     "shell.execute_reply": "2021-01-01T05:57:36.237310Z"
    },
    "papermill": {
     "duration": 0.017288,
     "end_time": "2021-01-01T05:57:36.237760",
     "exception": false,
     "start_time": "2021-01-01T05:57:36.220472",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# These parameters can be injected from Papermill\n",
    "model_type = \"pre_ln\"\n",
    "train_file = \"wikitext-103-raw/wiki.train.raw\"\n",
    "valid_file = \"wikitext-103-raw/wiki.valid.raw\"\n",
    "epochs = 10\n",
    "batch_size = 2\n",
    "max_learning_rate = 1e-4\n",
    "warmup_steps = 0\n",
    "save_model_dir = \"tfchat_model\"\n",
    "clipnorm = 1.0\n",
    "fp16 = False\n",
    "config_cls = \"tfchat.configs.GPT2SmallConfig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:36.265040Z",
     "iopub.status.busy": "2021-01-01T05:57:36.264679Z",
     "iopub.status.idle": "2021-01-01T05:57:36.266479Z",
     "shell.execute_reply": "2021-01-01T05:57:36.266111Z"
    },
    "papermill": {
     "duration": 0.016241,
     "end_time": "2021-01-01T05:57:36.266551",
     "exception": false,
     "start_time": "2021-01-01T05:57:36.250310",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "model_type = \"min_gpt\"\n",
    "save_model_dir = \"tfchat_model-min_gpt-lr_e4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:36.294029Z",
     "iopub.status.busy": "2021-01-01T05:57:36.293649Z",
     "iopub.status.idle": "2021-01-01T05:57:36.295621Z",
     "shell.execute_reply": "2021-01-01T05:57:36.295270Z"
    },
    "papermill": {
     "duration": 0.016527,
     "end_time": "2021-01-01T05:57:36.295692",
     "exception": false,
     "start_time": "2021-01-01T05:57:36.279165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assert parameters\n",
    "assert model_type in [\"pre_ln\", \"post_ln\", \"min_gpt\", \"transformers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01242,
     "end_time": "2021-01-01T05:57:36.320782",
     "exception": false,
     "start_time": "2021-01-01T05:57:36.308362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:36.349028Z",
     "iopub.status.busy": "2021-01-01T05:57:36.348668Z",
     "iopub.status.idle": "2021-01-01T05:57:41.343824Z",
     "shell.execute_reply": "2021-01-01T05:57:41.345516Z"
    },
    "papermill": {
     "duration": 5.012572,
     "end_time": "2021-01-01T05:57:41.346028",
     "exception": false,
     "start_time": "2021-01-01T05:57:36.333456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git is already the newest version (1:2.17.1-1ubuntu0.7).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
      "Collecting git+https://github.com/noriyukipy/tfchat@fp16\n",
      "  Cloning https://github.com/noriyukipy/tfchat (to revision fp16) to /tmp/pip-req-build-hyuhj2sp\n",
      "Requirement already satisfied (use --upgrade to upgrade): tfchat==0.1.0 from git+https://github.com/noriyukipy/tfchat@fp16 in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already satisfied: tensorflow~=2.0 in /usr/local/lib/python3.6/dist-packages (from tfchat==0.1.0) (2.3.1)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from tfchat==0.1.0) (0.1.91)\n",
      "Requirement already satisfied: scipy~=1.5.0 in /usr/local/lib/python3.6/dist-packages (from tfchat==0.1.0) (1.5.4)\n",
      "Requirement already satisfied: pydantic==1.6.1 in /usr/local/lib/python3.6/dist-packages (from tfchat==0.1.0) (1.6.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (3.13.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (1.32.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (1.15.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (2.10.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (1.18.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (0.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow~=2.0->tfchat==0.1.0) (0.30.0)\n",
      "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==1.6.1->tfchat==0.1.0) (0.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow~=2.0->tfchat==0.1.0) (50.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (1.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (3.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (2.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (4.1.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (3.6.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (0.4.8)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (3.0.1)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (4.7.6)\n",
      "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (1.6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp<4.0.0dev,>=3.6.2; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (20.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.0->tfchat==0.1.0) (3.2.0)\n",
      "Building wheels for collected packages: tfchat\n",
      "  Building wheel for tfchat (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tfchat: filename=tfchat-0.1.0-py3-none-any.whl size=14227 sha256=7dcf883756c1b9fdbafe708c056c03ed79b1054e2feab155bdd9421bcf60f334\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dy3c0mtv/wheels/f2/0d/98/190a24c7a12d4602852fb756e450d612cee0e0bf98d57f128d\n",
      "Successfully built tfchat\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt install -y git\n",
    "!pip install git+https://github.com/noriyukipy/tfchat@fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016097,
     "end_time": "2021-01-01T05:57:41.379524",
     "exception": false,
     "start_time": "2021-01-01T05:57:41.363427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:41.415277Z",
     "iopub.status.busy": "2021-01-01T05:57:41.414908Z",
     "iopub.status.idle": "2021-01-01T05:57:44.005763Z",
     "shell.execute_reply": "2021-01-01T05:57:44.005359Z"
    },
    "papermill": {
     "duration": 2.609861,
     "end_time": "2021-01-01T05:57:44.005857",
     "exception": false,
     "start_time": "2021-01-01T05:57:41.395996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tfchat.utils import set_memory_growth\n",
    "from tfchat.utils import set_mixed_precision_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:44.082673Z",
     "iopub.status.busy": "2021-01-01T05:57:44.082244Z",
     "iopub.status.idle": "2021-01-01T05:57:44.084722Z",
     "shell.execute_reply": "2021-01-01T05:57:44.084283Z"
    },
    "papermill": {
     "duration": 0.059701,
     "end_time": "2021-01-01T05:57:44.084818",
     "exception": false,
     "start_time": "2021-01-01T05:57:44.025117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set memory growth to PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "set_memory_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:44.124990Z",
     "iopub.status.busy": "2021-01-01T05:57:44.124632Z",
     "iopub.status.idle": "2021-01-01T05:57:44.126572Z",
     "shell.execute_reply": "2021-01-01T05:57:44.126216Z"
    },
    "papermill": {
     "duration": 0.021522,
     "end_time": "2021-01-01T05:57:44.126645",
     "exception": false,
     "start_time": "2021-01-01T05:57:44.105123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fp16:\n",
    "    set_mixed_precision_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01686,
     "end_time": "2021-01-01T05:57:44.160796",
     "exception": false,
     "start_time": "2021-01-01T05:57:44.143936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:44.200570Z",
     "iopub.status.busy": "2021-01-01T05:57:44.196367Z",
     "iopub.status.idle": "2021-01-01T05:57:45.584956Z",
     "shell.execute_reply": "2021-01-01T05:57:45.584560Z"
    },
    "papermill": {
     "duration": 1.407793,
     "end_time": "2021-01-01T05:57:45.585043",
     "exception": false,
     "start_time": "2021-01-01T05:57:44.177250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==3.4.0 in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2020.11.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.24.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (1.18.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n",
      "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.9.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.53.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.13.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.0.43)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.1.91)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==3.4.0) (2.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install transformers by HuggingFace to use GPT2 tokenizer\n",
    "! pip install transformers==3.4.0\n",
    "# Enable widgetsnbextention to avoid the following error when running GPT2.from_pretrained method\n",
    "#     ImportError: IProgress not found. Please update jupyter and ipywidgets.\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:45.624812Z",
     "iopub.status.busy": "2021-01-01T05:57:45.624433Z",
     "iopub.status.idle": "2021-01-01T05:57:47.393532Z",
     "shell.execute_reply": "2021-01-01T05:57:47.393160Z"
    },
    "papermill": {
     "duration": 1.790109,
     "end_time": "2021-01-01T05:57:47.393616",
     "exception": false,
     "start_time": "2021-01-01T05:57:45.603507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup tokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017538,
     "end_time": "2021-01-01T05:57:47.428909",
     "exception": false,
     "start_time": "2021-01-01T05:57:47.411371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:47.466000Z",
     "iopub.status.busy": "2021-01-01T05:57:47.465633Z",
     "iopub.status.idle": "2021-01-01T05:57:47.651650Z",
     "shell.execute_reply": "2021-01-01T05:57:47.651038Z"
    },
    "papermill": {
     "duration": 0.205726,
     "end_time": "2021-01-01T05:57:47.651779",
     "exception": false,
     "start_time": "2021-01-01T05:57:47.446053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tfchat.configs import GPT2SmallConfig\n",
    "from tfchat.utils import import_class\n",
    "\n",
    "config = import_class(config_cls)()\n",
    "\n",
    "# Set the larger number of vocab size than 33,278, which is the vocab size of Wikitext-2\n",
    "config.vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:47.704790Z",
     "iopub.status.busy": "2021-01-01T05:57:47.704399Z",
     "iopub.status.idle": "2021-01-01T05:57:47.706328Z",
     "shell.execute_reply": "2021-01-01T05:57:47.706626Z"
    },
    "papermill": {
     "duration": 0.029172,
     "end_time": "2021-01-01T05:57:47.706707",
     "exception": false,
     "start_time": "2021-01-01T05:57:47.677535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2SmallConfig(num_layers=12, d_model=768, num_heads=12, d_ff=3072, vocab_size=50257, context_size=1024, attention_dropout_rate=0.1, residual_dropout_rate=0.1, embedding_dropout_rate=0.1, activation='gelu', kernel_initializer='he_normal', epsilon=1e-06)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017487,
     "end_time": "2021-01-01T05:57:47.741702",
     "exception": false,
     "start_time": "2021-01-01T05:57:47.724215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:47.780706Z",
     "iopub.status.busy": "2021-01-01T05:57:47.780311Z",
     "iopub.status.idle": "2021-01-01T05:57:47.782121Z",
     "shell.execute_reply": "2021-01-01T05:57:47.781712Z"
    },
    "papermill": {
     "duration": 0.02307,
     "end_time": "2021-01-01T05:57:47.782232",
     "exception": false,
     "start_time": "2021-01-01T05:57:47.759162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def encode_file(_tokenizer, _filepath):\n",
    "    ids = []\n",
    "    with open(_filepath) as f:\n",
    "        for line in f.readlines():\n",
    "            text = line.strip(\"\\n\")\n",
    "            ids.extend(_tokenizer.encode(text))\n",
    "\n",
    "    return np.array(ids, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T05:57:47.821365Z",
     "iopub.status.busy": "2021-01-01T05:57:47.820980Z",
     "iopub.status.idle": "2021-01-01T06:05:16.952008Z",
     "shell.execute_reply": "2021-01-01T06:05:16.952305Z"
    },
    "papermill": {
     "duration": 449.151644,
     "end_time": "2021-01-01T06:05:16.952412",
     "exception": false,
     "start_time": "2021-01-01T05:57:47.800768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train_ids = encode_file(tokenizer, train_file)\n",
    "valid_ids = encode_file(tokenizer, valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T06:05:17.007980Z",
     "iopub.status.busy": "2021-01-01T06:05:17.007617Z",
     "iopub.status.idle": "2021-01-01T06:05:17.009225Z",
     "shell.execute_reply": "2021-01-01T06:05:17.009512Z"
    },
    "papermill": {
     "duration": 0.022797,
     "end_time": "2021-01-01T06:05:17.009598",
     "exception": false,
     "start_time": "2021-01-01T06:05:16.986801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (116755111,)\n",
      "Valid: (244828,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", train_ids.shape)\n",
    "print(\"Valid:\", valid_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T06:05:17.048099Z",
     "iopub.status.busy": "2021-01-01T06:05:17.047738Z",
     "iopub.status.idle": "2021-01-01T06:05:17.049761Z",
     "shell.execute_reply": "2021-01-01T06:05:17.049405Z"
    },
    "papermill": {
     "duration": 0.022097,
     "end_time": "2021-01-01T06:05:17.049832",
     "exception": false,
     "start_time": "2021-01-01T06:05:17.027735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116755111,)\n",
      "(244828,)\n"
     ]
    }
   ],
   "source": [
    "print(train_ids.shape)\n",
    "print(valid_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T06:05:17.089273Z",
     "iopub.status.busy": "2021-01-01T06:05:17.088911Z",
     "iopub.status.idle": "2021-01-01T06:05:18.615228Z",
     "shell.execute_reply": "2021-01-01T06:05:18.615650Z"
    },
    "papermill": {
     "duration": 1.547688,
     "end_time": "2021-01-01T06:05:18.615782",
     "exception": false,
     "start_time": "2021-01-01T06:05:17.068094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tfchat.data import BlockDataset\n",
    "\n",
    "\n",
    "dataset = BlockDataset(block_size=config.context_size, batch_size=batch_size)\n",
    "\n",
    "train_dataset = dataset.build(train_ids, shuffle=True)\n",
    "valid_dataset = dataset.build(valid_ids, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T06:05:18.657368Z",
     "iopub.status.busy": "2021-01-01T06:05:18.657004Z",
     "iopub.status.idle": "2021-01-01T06:07:13.184702Z",
     "shell.execute_reply": "2021-01-01T06:07:13.185017Z"
    },
    "papermill": {
     "duration": 114.549674,
     "end_time": "2021-01-01T06:07:13.185130",
     "exception": false,
     "start_time": "2021-01-01T06:05:18.635456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train steps: 57009\n",
      "Valid steps: 119\n"
     ]
    }
   ],
   "source": [
    "num_train_steps = len([_ for _ in train_dataset])\n",
    "num_valid_steps = len([_ for _ in valid_dataset])\n",
    "print(\"Train steps:\", num_train_steps)\n",
    "print(\"Valid steps:\", num_valid_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019031,
     "end_time": "2021-01-01T06:07:13.223779",
     "exception": false,
     "start_time": "2021-01-01T06:07:13.204748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transformers model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T06:07:13.263778Z",
     "iopub.status.busy": "2021-01-01T06:07:13.263403Z",
     "iopub.status.idle": "2021-01-01T06:07:13.266464Z",
     "shell.execute_reply": "2021-01-01T06:07:13.266097Z"
    },
    "papermill": {
     "duration": 0.024109,
     "end_time": "2021-01-01T06:07:13.266542",
     "exception": false,
     "start_time": "2021-01-01T06:07:13.242433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TFGPT2LMHeadModel\n",
    "from transformers import GPT2Config\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from tfchat.models import create_combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T06:07:13.308372Z",
     "iopub.status.busy": "2021-01-01T06:07:13.307997Z",
     "iopub.status.idle": "2021-01-01T06:07:13.309871Z",
     "shell.execute_reply": "2021-01-01T06:07:13.309534Z"
    },
    "papermill": {
     "duration": 0.024535,
     "end_time": "2021-01-01T06:07:13.309944",
     "exception": false,
     "start_time": "2021-01-01T06:07:13.285409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformersGPT2(keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        tf_config = GPT2Config(\n",
    "            n_layers=config.num_layers,\n",
    "            n_embd=config.d_model,\n",
    "            n_head=config.num_heads,\n",
    "            n_inner=config.d_ff,\n",
    "            vocab_size=config.vocab_size,\n",
    "            n_ctx=config.context_size,\n",
    "            n_positions=config.context_size,\n",
    "            attn_pdrop=config.attention_dropout_rate,\n",
    "            resid_pdrop=config.residual_dropout_rate,\n",
    "            embd_pdrop=config.embedding_dropout_rate,\n",
    "            layer_norm_epsilon=config.epsilon,\n",
    "            activation_function=\"gelu_new\",  # Default value of transformers implementation\n",
    "            \n",
    "        )\n",
    "        self._decoder = TFGPT2LMHeadModel(tf_config)\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        inputs = tf.cast(inputs, tf.int32)\n",
    "        x = self._decoder(inputs, training=training)\n",
    "        return x[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018787,
     "end_time": "2021-01-01T06:07:13.347635",
     "exception": false,
     "start_time": "2021-01-01T06:07:13.328848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T06:07:13.389088Z",
     "iopub.status.busy": "2021-01-01T06:07:13.388711Z",
     "iopub.status.idle": "2021-01-01T06:07:13.391407Z",
     "shell.execute_reply": "2021-01-01T06:07:13.391102Z"
    },
    "papermill": {
     "duration": 0.025186,
     "end_time": "2021-01-01T06:07:13.391484",
     "exception": false,
     "start_time": "2021-01-01T06:07:13.366298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tfchat.losses import PaddingLoss\n",
    "from tfchat.schedules import WarmupLinearDecay\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "\n",
    "def train(_model, _train_dataset, _valid_dataset, _epochs, _warmup_steps, _num_train_steps, _max_learning_rate, _clipnorm):\n",
    "    schedule = WarmupLinearDecay(max_learning_rate=_max_learning_rate,\n",
    "                                 warmup_steps=_warmup_steps,\n",
    "                                 training_steps=_num_train_steps*_epochs)\n",
    "    optimizer = keras.optimizers.Adam(schedule, beta_1=0.9, beta_2=0.999, epsilon=1e-8, clipnorm=_clipnorm)\n",
    "    _model.compile(loss=PaddingLoss(), optimizer=optimizer)\n",
    "\n",
    "\n",
    "    history = _model.fit(\n",
    "        _train_dataset,\n",
    "        validation_data=_valid_dataset,\n",
    "        epochs=_epochs,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(patience=1, restore_best_weights=True),\n",
    "            # If you want to save chekcpoints, remove the next comment out\n",
    "            #keras.callbacks.ModelCheckpoint(\"keras_model/\", save_best_only=True)\n",
    "        ],\n",
    "        verbose=2,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T06:07:13.432648Z",
     "iopub.status.busy": "2021-01-01T06:07:13.432274Z",
     "iopub.status.idle": "2021-01-01T06:07:13.643484Z",
     "shell.execute_reply": "2021-01-01T06:07:13.643145Z"
    },
    "papermill": {
     "duration": 0.233279,
     "end_time": "2021-01-01T06:07:13.643567",
     "exception": false,
     "start_time": "2021-01-01T06:07:13.410288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_type == \"pre_ln\":\n",
    "    from tfchat.models import PreLNDecoder\n",
    "    model = PreLNDecoder(config)\n",
    "elif model_type == \"post_ln\":\n",
    "    from tfchat.models import PostLNDecoder \n",
    "    model = PostLNDecoder(config)\n",
    "elif model_type == \"transformers\":\n",
    "    model = TransformersGPT2(config)\n",
    "elif model_type == \"min_gpt\":\n",
    "    from mingpt.model import GPT, GPTConfig\n",
    "    mconf = GPTConfig(config.vocab_size, config.context_size,\n",
    "                      n_layer=config.num_layers, n_head=config.num_heads, n_embd=config.d_model)\n",
    "    model = GPT(mconf)\n",
    "else:\n",
    "    raise Exception(\"Model type is wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T06:07:13.685564Z",
     "iopub.status.busy": "2021-01-01T06:07:13.683798Z",
     "iopub.status.idle": "2021-01-01T06:07:16.568910Z",
     "shell.execute_reply": "2021-01-01T06:07:16.569206Z"
    },
    "papermill": {
     "duration": 2.906522,
     "end_time": "2021-01-01T06:07:16.569303",
     "exception": false,
     "start_time": "2021-01-01T06:07:13.662781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  38597376  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "encoder_layer (EncoderLayer) multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_1 (EncoderLaye multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_2 (EncoderLaye multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_3 (EncoderLaye multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_4 (EncoderLaye multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_5 (EncoderLaye multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_6 (EncoderLaye multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_7 (EncoderLaye multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_8 (EncoderLaye multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_9 (EncoderLaye multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_10 (EncoderLay multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "encoder_layer_11 (EncoderLay multiple                  7087872   \n",
      "_________________________________________________________________\n",
      "layer_normalization_24 (Laye multiple                  1536      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             multiple                  38597376  \n",
      "=================================================================\n",
      "Total params: 163,037,184\n",
      "Trainable params: 163,037,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=(None, config.context_size))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T06:07:16.615244Z",
     "iopub.status.busy": "2021-01-01T06:07:16.614856Z",
     "iopub.status.idle": "2021-01-04T13:13:14.104100Z",
     "shell.execute_reply": "2021-01-04T13:13:14.104706Z"
    },
    "papermill": {
     "duration": 284757.516105,
     "end_time": "2021-01-04T13:13:14.104919",
     "exception": false,
     "start_time": "2021-01-01T06:07:16.588814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57009/57009 - 28382s - loss: 4.4434 - val_loss: 3.6543\n",
      "Epoch 2/10\n",
      "57009/57009 - 28428s - loss: 3.5601 - val_loss: 3.3607\n",
      "Epoch 3/10\n",
      "57009/57009 - 28469s - loss: 3.3275 - val_loss: 3.2273\n",
      "Epoch 4/10\n",
      "57009/57009 - 28642s - loss: 3.1922 - val_loss: 3.1583\n",
      "Epoch 5/10\n",
      "57009/57009 - 28446s - loss: 3.0954 - val_loss: 3.1084\n",
      "Epoch 6/10\n",
      "57009/57009 - 28394s - loss: 3.0188 - val_loss: 3.0746\n",
      "Epoch 7/10\n",
      "57009/57009 - 28433s - loss: 2.9543 - val_loss: 3.0467\n",
      "Epoch 8/10\n",
      "57009/57009 - 28510s - loss: 2.8982 - val_loss: 3.0271\n",
      "Epoch 9/10\n",
      "57009/57009 - 28407s - loss: 2.8488 - val_loss: 3.0125\n",
      "Epoch 10/10\n",
      "57009/57009 - 28539s - loss: 2.8065 - val_loss: 3.0021\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataset, valid_dataset, epochs, warmup_steps, num_train_steps, max_learning_rate, clipnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T13:13:14.159541Z",
     "iopub.status.busy": "2021-01-04T13:13:14.159101Z",
     "iopub.status.idle": "2021-01-04T13:13:29.013782Z",
     "shell.execute_reply": "2021-01-04T13:13:29.015445Z"
    },
    "papermill": {
     "duration": 14.887795,
     "end_time": "2021-01-04T13:13:29.015922",
     "exception": false,
     "start_time": "2021-01-04T13:13:14.128127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0020962, 'perplexity': 20.127686, 'num_batches': 119, 'num_tokens': 243712}\n",
      "Validation PPL: 20.127686\n"
     ]
    }
   ],
   "source": [
    "from tfchat.eval import perplexity\n",
    "\n",
    "print(\"Validation PPL:\", perplexity(model, valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T13:13:29.075077Z",
     "iopub.status.busy": "2021-01-04T13:13:29.066764Z",
     "iopub.status.idle": "2021-01-04T13:13:29.699905Z",
     "shell.execute_reply": "2021-01-04T13:13:29.699527Z"
    },
    "papermill": {
     "duration": 0.660045,
     "end_time": "2021-01-04T13:13:29.699988",
     "exception": false,
     "start_time": "2021-01-04T13:13:29.039943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tfchat.utils import save_model\n",
    "\n",
    "save_model(save_model_dir, model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.022998,
     "end_time": "2021-01-04T13:13:29.746156",
     "exception": false,
     "start_time": "2021-01-04T13:13:29.723158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "papermill": {
   "duration": 285360.098579,
   "end_time": "2021-01-04T13:13:35.470672",
   "environment_variables": {},
   "exception": null,
   "input_path": "tfmodel_train_scratch.ipynb",
   "output_path": "output/tfmodel_train_scratch-wikitext_103_raw-min_gpt-lr_e4.ipynb",
   "parameters": {
    "model_type": "min_gpt",
    "save_model_dir": "tfchat_model-min_gpt-lr_e4"
   },
   "start_time": "2021-01-01T05:57:35.372093",
   "version": "2.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
