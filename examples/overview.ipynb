{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pre_ln_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder (Decoder)            multiple                  312804    \n",
      "=================================================================\n",
      "Total params: 312,804\n",
      "Trainable params: 312,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.8641 - val_loss: 9.0693e-05\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 5s 61ms/step - loss: 0.0049 - val_loss: 1.7060e-04\n",
      "{'loss': 9.0920184e-05, 'perplexity': 1.000091, 'num_batches': 7, 'num_tokens': 807}\n",
      "Validation PPL: 1.000091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5, 6, 7, 8]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tfchat.configs import Config\n",
    "from tfchat.data import BlockDataset\n",
    "from tfchat.metrics import perplexity\n",
    "from tfchat.losses import PaddingLoss\n",
    "from tfchat.schedules import WarmupLinearDecay\n",
    "from tfchat.generations import TopKTopPGenerator\n",
    "from tfchat.models import PreLNDecoder\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define model config\n",
    "config = Config(num_layers=6, d_model=64, num_heads=1, d_ff=256, vocab_size=100,\n",
    "                context_size=64, attention_dropout_rate=0.1, residual_dropout_rate=0.1,\n",
    "                embedding_dropout_rate=0.1, epsilon=1e-06)\n",
    "\n",
    "# You can use predefined config as follows instead of defining config by yourself\n",
    "#\n",
    "# from tfchat.configs import GPT2SmallConfig\n",
    "# config = GPT2SmallConfig()\n",
    "\n",
    "\n",
    "# Define training parameters\n",
    "batch_size = 2\n",
    "epochs = 10\n",
    "\n",
    "# Prepare dataset\n",
    "train_ids = np.tile(np.arange(10, dtype=np.int32), 1000)  # Prepare token ids for training data\n",
    "valid_ids = np.tile(np.arange(10, dtype=np.int32), 100)   # Prepare token ids for validation data\n",
    "\n",
    "dataset = BlockDataset(block_size=config.context_size, batch_size=batch_size)\n",
    "train_dataset = dataset.build(train_ids, shuffle=True)\n",
    "valid_dataset = dataset.build(valid_ids, shuffle=False)\n",
    "\n",
    "# Prepare model\n",
    "num_steps = len([_ for _ in train_dataset])\n",
    "schedule = WarmupLinearDecay(max_learning_rate=1e-3, warmup_steps=0, training_steps=num_steps*epochs)\n",
    "optimizer = keras.optimizers.Adam(schedule, beta_1=0.9, beta_2=0.999, epsilon=1e-8, clipnorm=1.0)\n",
    "\n",
    "model = PreLNDecoder(config)\n",
    "model.compile(loss=PaddingLoss(), optimizer=optimizer)\n",
    "model.build(input_shape=(None, config.context_size))\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=1, restore_best_weights=True),\n",
    "        # If you want to save chekcpoints, remove the next comment out\n",
    "        #keras.callbacks.ModelCheckpoint(\"keras_model/\", save_best_only=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "ppl = perplexity(model, valid_dataset)\n",
    "print(\"Validation PPL:\", ppl)\n",
    "\n",
    "# Generate\n",
    "gen = TopKTopPGenerator(model=model, max_len=3)\n",
    "inputs = np.array([[1, 2, 3, 4, 5]], dtype=np.int32)\n",
    "gen.generate(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
