{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016151,
     "end_time": "2020-10-25T05:33:25.665485",
     "exception": false,
     "start_time": "2020-10-25T05:33:25.649334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:25.689058Z",
     "iopub.status.busy": "2020-10-25T05:33:25.688693Z",
     "iopub.status.idle": "2020-10-25T05:33:25.690593Z",
     "shell.execute_reply": "2020-10-25T05:33:25.690225Z"
    },
    "papermill": {
     "duration": 0.014613,
     "end_time": "2020-10-25T05:33:25.690669",
     "exception": false,
     "start_time": "2020-10-25T05:33:25.676056",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# These parameters can be injected from Papermill\n",
    "model_type = \"pre_ln\"\n",
    "train_file = \"wikitext-103-raw/wiki.train.raw\"\n",
    "valid_file = \"wikitext-103-raw/wiki.valid.raw\"\n",
    "epochs = 10\n",
    "batch_size = 2\n",
    "max_learning_rate = 1e-4\n",
    "warmup_steps = 0\n",
    "clipnorm = 1.0\n",
    "fp16 = False\n",
    "save_model_dir = f\"output/tfdlg_train-{model_type}-model\"\n",
    "tensorboard_dir = f\"output/tensorboard/{save_model_dir}-tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert parameters\n",
    "assert model_type in [\"pre_ln\", \"post_ln\", \"transformers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010568,
     "end_time": "2020-10-25T05:33:25.736850",
     "exception": false,
     "start_time": "2020-10-25T05:33:25.726282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:25.760210Z",
     "iopub.status.busy": "2020-10-25T05:33:25.759851Z",
     "iopub.status.idle": "2020-10-25T05:33:26.667402Z",
     "shell.execute_reply": "2020-10-25T05:33:26.667026Z"
    },
    "papermill": {
     "duration": 0.920123,
     "end_time": "2020-10-25T05:33:26.667484",
     "exception": false,
     "start_time": "2020-10-25T05:33:25.747361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tfdlg.utils import set_memory_growth\n",
    "from tfdlg.utils import set_mixed_precision_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:27.227136Z",
     "iopub.status.busy": "2020-10-25T05:33:27.226761Z",
     "iopub.status.idle": "2020-10-25T05:33:27.228837Z",
     "shell.execute_reply": "2020-10-25T05:33:27.228486Z"
    },
    "papermill": {
     "duration": 0.55073,
     "end_time": "2020-10-25T05:33:27.228969",
     "exception": false,
     "start_time": "2020-10-25T05:33:26.678239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_memory_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fp16:\n",
    "    set_mixed_precision_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010916,
     "end_time": "2020-10-25T05:33:27.251283",
     "exception": false,
     "start_time": "2020-10-25T05:33:27.240367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:27.275657Z",
     "iopub.status.busy": "2020-10-25T05:33:27.275297Z",
     "iopub.status.idle": "2020-10-25T05:33:28.686226Z",
     "shell.execute_reply": "2020-10-25T05:33:28.684139Z"
    },
    "papermill": {
     "duration": 1.424651,
     "end_time": "2020-10-25T05:33:28.686639",
     "exception": false,
     "start_time": "2020-10-25T05:33:27.261988",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install transformers by HuggingFace to use GPT2 tokenizer\n",
    "! pip install transformers==3.4.0\n",
    "# Enable widgetsnbextention to avoid the following error when running GPT2.from_pretrained method\n",
    "#     ImportError: IProgress not found. Please update jupyter and ipywidgets.\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:28.753379Z",
     "iopub.status.busy": "2020-10-25T05:33:28.752961Z",
     "iopub.status.idle": "2020-10-25T05:33:30.435232Z",
     "shell.execute_reply": "2020-10-25T05:33:30.434905Z"
    },
    "papermill": {
     "duration": 1.701922,
     "end_time": "2020-10-25T05:33:30.435314",
     "exception": false,
     "start_time": "2020-10-25T05:33:28.733392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup tokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012068,
     "end_time": "2020-10-25T05:33:30.459683",
     "exception": false,
     "start_time": "2020-10-25T05:33:30.447615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:30.486382Z",
     "iopub.status.busy": "2020-10-25T05:33:30.485982Z",
     "iopub.status.idle": "2020-10-25T05:33:30.556179Z",
     "shell.execute_reply": "2020-10-25T05:33:30.555801Z"
    },
    "papermill": {
     "duration": 0.084744,
     "end_time": "2020-10-25T05:33:30.556263",
     "exception": false,
     "start_time": "2020-10-25T05:33:30.471519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tfdlg.configs import GPT2SmallConfig\n",
    "\n",
    "config = GPT2SmallConfig()\n",
    "\n",
    "# Set the larger number of vocab size than 33,278, which is the vocab size of Wikitext-2\n",
    "config.vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:30.586907Z",
     "iopub.status.busy": "2020-10-25T05:33:30.586539Z",
     "iopub.status.idle": "2020-10-25T05:33:30.588803Z",
     "shell.execute_reply": "2020-10-25T05:33:30.588501Z"
    },
    "papermill": {
     "duration": 0.020325,
     "end_time": "2020-10-25T05:33:30.588878",
     "exception": false,
     "start_time": "2020-10-25T05:33:30.568553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012416,
     "end_time": "2020-10-25T05:33:30.613934",
     "exception": false,
     "start_time": "2020-10-25T05:33:30.601518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:30.642368Z",
     "iopub.status.busy": "2020-10-25T05:33:30.642003Z",
     "iopub.status.idle": "2020-10-25T05:33:30.643921Z",
     "shell.execute_reply": "2020-10-25T05:33:30.643566Z"
    },
    "papermill": {
     "duration": 0.017599,
     "end_time": "2020-10-25T05:33:30.643992",
     "exception": false,
     "start_time": "2020-10-25T05:33:30.626393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_file(_filepath):\n",
    "    return (t.strip(\"\\n\") for t in open(_filepath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:43.399711Z",
     "iopub.status.busy": "2020-10-25T05:33:43.399328Z",
     "iopub.status.idle": "2020-10-25T05:33:43.457643Z",
     "shell.execute_reply": "2020-10-25T05:33:43.457266Z"
    },
    "papermill": {
     "duration": 0.484628,
     "end_time": "2020-10-25T05:33:43.457723",
     "exception": false,
     "start_time": "2020-10-25T05:33:42.973095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tfdlg.data import BlockDataset\n",
    "\n",
    "\n",
    "train_dataset = BlockDataset.from_generator(\n",
    "    generator=lambda: read_file(train_file),\n",
    "    encode_fn=tokenizer.encode,\n",
    "    block_size=config.context_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "valid_dataset = BlockDataset.from_generator(\n",
    "    generator=lambda: read_file(valid_file),\n",
    "    encode_fn=tokenizer.encode,\n",
    "    block_size=config.context_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:43.486666Z",
     "iopub.status.busy": "2020-10-25T05:33:43.486305Z",
     "iopub.status.idle": "2020-10-25T05:33:43.488125Z",
     "shell.execute_reply": "2020-10-25T05:33:43.487771Z"
    },
    "papermill": {
     "duration": 0.017,
     "end_time": "2020-10-25T05:33:43.488196",
     "exception": false,
     "start_time": "2020-10-25T05:33:43.471196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_train_steps = sum(1 for _ in train_dataset)\n",
    "num_valid_steps = sum(1 for _ in valid_dataset)\n",
    "print(\"Train steps:\", num_train_steps)\n",
    "print(\"Valid steps:\", num_valid_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFGPT2LMHeadModel\n",
    "from transformers import GPT2Config\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersGPT2(keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        tf_config = GPT2Config(\n",
    "            n_layers=config.num_layers,\n",
    "            n_embd=config.d_model,\n",
    "            n_head=config.num_heads,\n",
    "            n_inner=config.d_ff,\n",
    "            vocab_size=config.vocab_size,\n",
    "            n_ctx=config.context_size,\n",
    "            n_positions=config.context_size,\n",
    "            attn_pdrop=config.attention_dropout_rate,\n",
    "            resid_pdrop=config.residual_dropout_rate,\n",
    "            embd_pdrop=config.embedding_dropout_rate,\n",
    "            layer_norm_epsilon=config.epsilon,\n",
    "            activation_function=\"gelu_new\",  # Default value of transformers implementation\n",
    "            \n",
    "        )\n",
    "        self._decoder = TFGPT2LMHeadModel(tf_config)\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        inputs = tf.cast(inputs, tf.int32)\n",
    "        x = self._decoder(inputs, training=training)\n",
    "        return x[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013209,
     "end_time": "2020-10-25T05:33:43.514599",
     "exception": false,
     "start_time": "2020-10-25T05:33:43.501390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:43.545423Z",
     "iopub.status.busy": "2020-10-25T05:33:43.545055Z",
     "iopub.status.idle": "2020-10-25T05:33:43.547469Z",
     "shell.execute_reply": "2020-10-25T05:33:43.547116Z"
    },
    "papermill": {
     "duration": 0.019812,
     "end_time": "2020-10-25T05:33:43.547540",
     "exception": false,
     "start_time": "2020-10-25T05:33:43.527728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tfdlg.losses import PaddingLoss\n",
    "from tfdlg.schedules import WarmupLinearDecay\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "\n",
    "def train(\n",
    "    _model,\n",
    "    _train_dataset,\n",
    "    _valid_dataset,\n",
    "    _epochs,\n",
    "    _warmup_steps,\n",
    "    _num_train_steps,\n",
    "    _max_learning_rate,\n",
    "    _clipnorm,\n",
    "    _tensorboard_dir\n",
    "):\n",
    "    schedule = WarmupLinearDecay(\n",
    "        max_learning_rate=_max_learning_rate,\n",
    "        warmup_steps=_warmup_steps,\n",
    "        training_steps=_num_train_steps*_epochs\n",
    "    )\n",
    "    optimizer = keras.optimizers.Adam(schedule, beta_1=0.9, beta_2=0.999, epsilon=1e-8, clipnorm=_clipnorm)\n",
    "    _model.compile(loss=PaddingLoss(), optimizer=optimizer)\n",
    "\n",
    "    history = _model.fit(\n",
    "        _train_dataset,\n",
    "        validation_data=_valid_dataset,\n",
    "        epochs=_epochs,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(patience=1, restore_best_weights=True),\n",
    "            keras.callbacks.TensorBoard(\n",
    "                log_dir=tensorboard_dir,\n",
    "                update_freq=100,\n",
    "                profile_batch=0,\n",
    "            )\n",
    "        ],\n",
    "        verbose=2,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"pre_ln\":\n",
    "    from tfdlg.models import PreLNDecoder\n",
    "    model = PreLNDecoder(config)\n",
    "elif model_type == \"post_ln\":\n",
    "    from tfdlg.models import PostLNDecoder \n",
    "    model = PostLNDecoder(config)\n",
    "elif model_type == \"transformers\":\n",
    "    model = TransformersGPT2(config)\n",
    "else:\n",
    "    raise Exception(\"Model type is wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, config.context_size))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-25T05:33:43.860584Z",
     "iopub.status.busy": "2020-10-25T05:33:43.860221Z"
    },
    "papermill": {
     "duration": 535.285785,
     "end_time": "2020-10-25T05:42:39.126238",
     "exception": false,
     "start_time": "2020-10-25T05:33:43.840453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    valid_dataset,\n",
    "    epochs,\n",
    "    warmup_steps,\n",
    "    num_train_steps,\n",
    "    max_learning_rate,\n",
    "    clipnorm,\n",
    "    tensorboard_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfdlg.eval import perplexity\n",
    "\n",
    "print(\"Validation PPL:\", perplexity(model, valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfdlg.utils import save_model\n",
    "\n",
    "save_model(save_model_dir, model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "duration": 555.416472,
   "end_time": "2020-10-25T05:42:40.406950",
   "environment_variables": {},
   "exception": null,
   "input_path": "tfmodel_train_scratch.ipynb",
   "output_path": "tfmodel_train_scratch-wikitext2.ipynb",
   "parameters": {
    "epochs": 1,
    "train_file": "wikitext-2-raw/wiki.train.raw",
    "valid_file": "wikitext-2-raw/wiki.valid.raw"
   },
   "start_time": "2020-10-25T05:33:24.990478",
   "version": "2.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
